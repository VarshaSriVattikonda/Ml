{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEhvlGtOIHMM3n/HPSIkyX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VarshaSriVattikonda/Ml/blob/main/Untitled20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXXVUMwEeME_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('Reviews.csv')"
      ],
      "metadata": {
        "id": "E3svTqPNew7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n"
      ],
      "metadata": {
        "id": "mqixqbIPfJIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())  # Tokenization\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words and word.isalpha()]  # Removing stop words\n",
        "    return ' '.join(filtered_tokens)"
      ],
      "metadata": {
        "id": "wvlX4otkfcrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['processed_text'] = train_data['Text'].astype(str).apply(preprocess_text)\n",
        "test_data['processed_text'] = test_data['Text'].astype(str).apply(preprocess_text)"
      ],
      "metadata": {
        "id": "ZWxJs7QSfgvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(train_data['processed_text'])\n",
        "\n"
      ],
      "metadata": {
        "id": "euR0ghiKfsjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_set = set()\n",
        "for _, row in train_data.iterrows():\n",
        "    word_set.update(row['Processed_Text'])"
      ],
      "metadata": {
        "id": "0aA70gpifv3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sequences = tokenizer.texts_to_sequences(train_data['Processed_Text'])\n",
        "test_sequences = tokenizer.texts_to_sequences(test_data['Processed_Text'])"
      ],
      "metadata": {
        "id": "LuqXpLXDqxq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1"
      ],
      "metadata": {
        "id": "tZiTtpCimZV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))"
      ],
      "metadata": {
        "id": "EYriIP1wmg8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word, i in word_index.items():\n",
        "    embedding_vector = np.random.uniform(-1, 1, embedding_dim)  # Random initialization\n",
        "    embedding_matrix[i] = embedding_vector\n"
      ],
      "metadata": {
        "id": "i_-eg0u1mkoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_sentiment(review):\n",
        "    positive_words = ['good', 'great', 'excellent']  # Add more positive words as needed\n",
        "    negative_words = ['bad', 'poor', 'worst']  # Add more negative words as needed\n",
        "\n",
        "    positive_count = sum([1 for word in review.split() if word in positive_words])\n",
        "    negative_count = sum([1 for word in review.split() if word in negative_words])\n",
        "\n",
        "    if positive_count > negative_count:\n",
        "        return 'Positive'\n",
        "    elif positive_count < negative_count:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'"
      ],
      "metadata": {
        "id": "7r69bBkom0Lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['sentiment'] = train_data['processed_text'].apply(classify_sentiment)\n",
        "test_data['sentiment'] = test_data['processed_text'].apply(classify_sentiment)\n",
        "\n",
        "train_positive_count = (train_data['sentiment'] == 'Positive').sum()\n",
        "train_negative_count = (train_data['sentiment'] == 'Negative').sum()\n",
        "\n",
        "test_positive_count = (test_data['sentiment'] == 'Positive').sum()\n",
        "test_negative_count = (test_data['sentiment'] == 'Negative').sum()"
      ],
      "metadata": {
        "id": "DaqzNaE2m7-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Data:\")\n",
        "print(\"Number of Positive Reviews:\", train_positive_count)\n",
        "print(\"Number of Negative Reviews:\", train_negative_count)\n",
        "\n",
        "print(\"\\nTesting Data:\")\n",
        "print(\"Number of Positive Reviews:\", test_positive_count)\n",
        "print(\"Number of Negative Reviews:\", test_negative_count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrVGgOFDnHlV",
        "outputId": "b0c204e2-b9a8-4a4f-e5e8-bd45e6150859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data:\n",
            "Number of Positive Reviews: 2289\n",
            "Number of Negative Reviews: 172\n",
            "\n",
            "Testing Data:\n",
            "Number of Positive Reviews: 569\n",
            "Number of Negative Reviews: 38\n"
          ]
        }
      ]
    }
  ]
}